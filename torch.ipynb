{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbeaf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -2.],\n",
       "       [ 3.,  4.]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,-2],[3,4]])\n",
    "np.asarray(tensor,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1, -2],\n",
       "        [ 3,  4]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([[1,-2],[3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca152a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros([2,3],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5240c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn([2,3,4])\n",
    "print(A.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6af66ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0895,  1.1080, -1.6489, -0.7532],\n",
       "         [-0.8828,  0.1302,  0.6551,  1.3951],\n",
       "         [-0.3154,  2.0570, -0.1522,  0.9927]],\n",
       "\n",
       "        [[-0.0507, -0.2976,  0.0488, -1.4601],\n",
       "         [ 2.3502, -0.5971,  0.5370, -0.7987],\n",
       "         [-0.7335, -0.7927,  0.6118, -1.0961]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea4867c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0895, -0.0507],\n",
       "         [-0.8828,  2.3502],\n",
       "         [-0.3154, -0.7335]],\n",
       "\n",
       "        [[ 1.1080, -0.2976],\n",
       "         [ 0.1302, -0.5971],\n",
       "         [ 2.0570, -0.7927]],\n",
       "\n",
       "        [[-1.6489,  0.0488],\n",
       "         [ 0.6551,  0.5370],\n",
       "         [-0.1522,  0.6118]],\n",
       "\n",
       "        [[-0.7532, -1.4601],\n",
       "         [ 1.3951, -0.7987],\n",
       "         [ 0.9927, -1.0961]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_t = torch.transpose(A,0,2) # Pour  transpose un tenseur\n",
    "A_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0860f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "A1 = torch.randint(0,10 ,[4,4]) # tenseur de nombre entier entre 0 et 10 de dimention (4,4)\n",
    "print(A1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa5db93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 8, 6, 9, 2, 2, 0, 0],\n",
      "        [7, 8, 6, 3, 7, 3, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(A1.view([2,8]))  # Reshape en numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ead585c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 8, 6, 9, 2, 2, 0, 0, 7, 8, 6, 3, 7, 3, 1, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A1.flatten() # Applatir un tenseur (Mettre à plat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea1d4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = torch.randint([2,2] ,dtype=torch.float32)  # Change de type des elements de tenseur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e7e8ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation de reseau de neuronne\n",
    "from torch.nn import functional as F\n",
    "class MyModel(nn.Module):\n",
    "    '''\n",
    "    Basic fully connected neural nets\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        hidden1 = 100  # premiere couche dense\n",
    "        hidden2 = 100  # Deuxieme couche dense\n",
    "\n",
    "        super(MyModel,self).__init__()\n",
    "        self.hidden1 = nn.Linear(784,hidden1)\n",
    "        self.hidden2 = nn.Linear(hidden1,hidden2)\n",
    "        self.hidden3 = nn.Linear(hidden2,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784)\n",
    "        x = self.hidden1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.hidden2(x)\n",
    "        x = F.relu(x)\n",
    "        x= self.hidden3(x)\n",
    "        x = F.softmax(x,dim=0)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a77230c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : tensor([[-1.3713, -0.0372],\n",
      "        [-1.2773, -0.1526],\n",
      "        [-1.4984,  0.1996],\n",
      "        [-1.1352,  0.8985],\n",
      "        [-2.4580, -0.3736]])\n",
      "w : tensor([-1.0358, -0.9755], requires_grad=True)\n",
      "y_pred : tensor([1.4568, 1.4720, 1.3574, 0.2994, 2.9105], grad_fn=<AddBackward0>)\n",
      "X.grad : None\n",
      "w.grad : None\n",
      "y_pred.grad : None\n"
     ]
    }
   ],
   "source": [
    "X  = torch.randn([5,2],requires_grad=False)  #  requires_grad=False => je ne veux pas calculer la grad de X\n",
    "w = torch.randn([2],requires_grad=True)  #  requires_grad=True => je  veux  calculer la grad de X (car mon params à estimer)\n",
    "\n",
    "y_pred = w[0]*X[:,0] + w[1]*X[:,1]\n",
    "y_pred.retain_grad()\n",
    "\n",
    "print('X :',X)\n",
    "print('w :',w)\n",
    "print('y_pred :',y_pred)\n",
    "\n",
    "print('X.grad :',X.grad)\n",
    "print('w.grad :',w.grad)\n",
    "print('y_pred.grad :',y_pred.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74160f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_true : tensor([0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "y_true = torch.zeros([5],requires_grad=False)\n",
    "print('y_true :',y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk = (torch.pow(y_pred - y_true,2)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adadf5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc07310c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.grad : None\n"
     ]
    }
   ],
   "source": [
    "print('X.grad :',X.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ac42c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.grad : tensor([0.5827, 0.5888, 0.5430, 0.1198, 1.1642])\n"
     ]
    }
   ],
   "source": [
    "print('y_pred.grad :' ,y_pred.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58cb11f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.grad : tensor([-5.3623, -0.3305])\n"
     ]
    }
   ],
   "source": [
    "print('w.grad :' ,w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d6b5d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True)\n",
      "y : tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<PowBackward0>)\n",
      "z : tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], grad_fn=<PowBackward0>)\n",
      "r : tensor(20., grad_fn=<SumBackward0>)\n",
      "x.grad : tensor([5., 5., 5., 5., 5., 5., 5., 5., 5., 5.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(10,requires_grad=True)\n",
    "y = x**2\n",
    "z = x**3\n",
    "r = (y+z).sum()\n",
    "r.backward()\n",
    "print('X :' ,x)\n",
    "print('y :' ,y)\n",
    "print('z :',z)\n",
    "print('r :',r)\n",
    "print('x.grad :',x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e86ae17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2.])\n",
      "Z : tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(10 ,requires_grad=True)\n",
    "y = x**2\n",
    "z = x.detach()**3  # Version de x mais constante,requires_grad=False\n",
    "\n",
    "r = (y+z).sum()\n",
    "r.backward()\n",
    "\n",
    "print(x.grad)\n",
    "\n",
    "print('Z :',z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "742bb930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r : tensor(6., grad_fn=<SumBackward0>)\n",
      "x.grad : tensor([5., 5., 5.])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3,requires_grad=True)\n",
    "y = x**2\n",
    "z = x**3\n",
    "r = (y + z).sum() # [1^2 + 1^3 ,1^2 + 1^3 ,1^2 + 1^3 ]\n",
    "r.backward()\n",
    "\n",
    "\n",
    "print('r :',r)\n",
    "print('x.grad :',x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f15ecaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r : tensor(6.)\n",
      "x.grad : None\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(3 ,requires_grad=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y = x**2\n",
    "    z = x**3\n",
    "    r = (y + z).sum()\n",
    "\n",
    "print('r :',r)\n",
    "print('x.grad :',x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "886b2695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda disponible  False\n",
      "Nombre de divice  0\n"
     ]
    }
   ],
   "source": [
    "print('Cuda disponible ',torch.cuda.is_available())\n",
    "print(\"Nombre de divice \",torch.cuda.device_count())\n",
    "# print('Divice utilisé ',torch.cuda.current_device())\n",
    "# print(\"Nom de divice utilisé \",torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf701c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models  # models sont des architecture de reseau de neurone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7bae8c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "tensor([[ 0.2890,  0.7769,  0.6935, -0.0172,  0.1026],\n",
      "        [ 0.1473, -0.1413,  1.1240,  0.3921,  0.3124],\n",
      "        [-0.3302,  0.6143,  0.7208, -0.8872,  0.1771],\n",
      "        [ 0.4967,  0.0390,  0.8098,  0.4202,  0.0267],\n",
      "        [-0.1354,  0.4659,  0.8234,  0.1549,  0.2837],\n",
      "        [-0.0594,  0.7901,  1.0194, -0.4028,  0.3162],\n",
      "        [ 0.4391,  0.6061,  0.2670, -0.0771,  0.5034],\n",
      "        [-0.0623,  0.8036,  0.8625, -0.2208,  0.3027],\n",
      "        [ 0.2007,  0.4821,  0.7175,  0.3549, -0.1862],\n",
      "        [ 0.3553,  0.4015,  0.7078,  0.2525, -0.0329]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cude:0' if torch.cuda.is_available() else 'cpu') # DEVICE = \"gpu\" s'il existe ,sinon \"cpu\"\n",
    "print(DEVICE)\n",
    "\n",
    "h_resnet18 = models.resnet18() # h_resnet18 :host_de reseau de neuronne18\n",
    "h_resnet18.fc = nn.Linear(512,5)\n",
    "\n",
    "d_resnet18 = h_resnet18.to(DEVICE) # d_ :device , d_resnet18 = h_resnet18.cuda()\n",
    "\n",
    "h_simulted_data = torch.randn([1000,3,64,64])\n",
    "d_mini_batch = h_simulted_data[0:10,:,:,:].to(DEVICE) # Transfere sur le gpu s'il existe\n",
    "\n",
    "d_outputs = d_resnet18(d_mini_batch)\n",
    "h_outputs = d_outputs.to('cpu') # Transfere sur le cpu ,h_outputs = d_outputs.cpu()\n",
    "\n",
    "print(h_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9179bd2",
   "metadata": {},
   "source": [
    "# 1) Etude d'un exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45929748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision   # To get the MNIST data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "13ef6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and format the training set\n",
    "mnist_trainset = torchvision.datasets.MNIST(root='./data',train=True ,download=False ,transform=None)\n",
    "x_train = mnist_trainset.data.type(torch.DoubleTensor)\n",
    "y_train = mnist_trainset.targets\n",
    "\n",
    "# Get and format the test set\n",
    "mnist_testset = torchvision.datasets.MNIST(root='./data' ,train=False ,download=False ,transform=None)\n",
    "x_test = mnist_testset.data.type(torch.DoubleTensor)\n",
    "y_test = mnist_testset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "792a3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel().to(DEVICE) # Mettre dans le carte GPU s'il exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cda442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'entrainement \n",
    "def fit(model,X_train,Y_train,X_test,Y_tetst,EPOCHS=5,BATCH_SIZE =32):\n",
    "    loss = nn.CrossEntropyLoss()  # Fonction de perte (cross entropy)\n",
    "    optimezer = torch.optim.Adam(model.parameters(),lr=1e-3) # Methode de minimisation (Adam)\n",
    "    model.train()  # N'est pas necessaire\n",
    "\n",
    "    history = n\n",
    "\n",
    "    n = X_train.shape[0] # Nombre d'observation\n",
    "\n",
    "    #stochastic gradient descent\n",
    "    for epoch in EPOCHS:  # Parcourir tous les observation de l'ordre aleatoire par epoch\n",
    "        batch_start = 0\n",
    "        epoch_shuffler = np.arange(n) \n",
    "        np.random.shuffle(epoch_shuffler)\n",
    "\n",
    "        while batch_start + BATCH_SIZE < n:\n",
    "            # Get mini_batch observation\n",
    "            mini_batch_observation = epoch_shuffler[batch_start : batch_start+BATCH_SIZE]\n",
    "            var_X_batch = X_train[mini_batch_observation,:,:].float().to(DEVICE)  # Observation de chaque mini_batch\n",
    "            var_Y_batch = Y_train[mini_batch_observation]\n",
    "\n",
    "            #Gradient descent step\n",
    "            optimezer.zero_grad() # Mise à zero des paramètree du modele\n",
    "            Y_pred_batch = model(var_X_batch)  #Faire la prediction des sorties avec les parametres du modeles courant\n",
    "            curr_loss = loss(Y_pred_batch.to('cpu'),var_Y_batch) # Calcule de  du loss dans le cpu pour tous les observation de mini-batch\n",
    "            curr_loss.backward() # Calcul de gradient de tous les variable d'entre (Backpropagation)\n",
    "            optimezer.step() # mettre à jour les params de NN par le nouveau valeur calculer par le gradient\n",
    "\n",
    "            # Prepare the next mini_batch of epoch\n",
    "            batch_start += BATCH_SIZE\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23d0cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
